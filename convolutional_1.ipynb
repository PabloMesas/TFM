{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17VBdqomreofRALqlfF0XsI5hEQfrX4-E",
      "authorship_tag": "ABX9TyOc/WPZz6spf7zFn0qp1JO2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RurXunB-6nMi"
      },
      "source": [
        "\n",
        "\n",
        "Install dependencies\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10PyY7GC6uCw",
        "outputId": "d4d77646-0d9b-4085-a992-82e015f426b1"
      },
      "source": [
        "!pip3 install tensorflow==2.2 keras simpleitk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.2 in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: simpleitk in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (2.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.34.1)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (2.2.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.6.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (57.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.32.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZjU4w5ofRBu"
      },
      "source": [
        "# !pip install git+https://github.com/JihongJu/keras-resnet3d.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZLhEj--wJHW"
      },
      "source": [
        "Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7hrgrNuu1KS"
      },
      "source": [
        "import os\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #then these two lines force keras to use your CPU\n",
        "# import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "# from keras.layers import Dense, Dropout, Activation, Flatten, Lambda\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras.layers.normalization import BatchNormalization as BN\n",
        "# from keras.layers import GaussianNoise as GN\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, MaxPool3D, GlobalAveragePooling3D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.python.keras.utils import data_utils\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from skimage import data\n",
        "from skimage.util import montage \n",
        "import skimage.transform as skTrans\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "#from skimage.transform import resiz\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import SimpleITK as sitk\n",
        "import nibabel as nib"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znqIEoxb4034"
      },
      "source": [
        "**Load and prepare data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucs3UqFi5ok8",
        "outputId": "d7d94588-f981-4d7f-dc2d-8f06ff386811"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_dir = \"drive/MyDrive/Colab Notebooks/TFM/DATA/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo3skwY9J8Gf"
      },
      "source": [
        "batch_size = 1\n",
        "epochs = 100\n",
        "# frozen_epochs = 100\n",
        "num_classes = 3\n",
        "images_shape = (192,192,160)\n",
        "n_channels = 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQedEJul6I9H"
      },
      "source": [
        "# # img_route = project_dir  + 'AD/002_S_0619_I48617/002_S_0619_I48617_masked.nii.gz'\n",
        "# # img_route = project_dir  + 'AD/002_S_0619_I48617/002_S_0619_I48617_masked_basic.nii.gz'\n",
        "# img_route = project_dir  + 'Train/AD/023_S_0139_I31300_masked_basic.nii.gz'\n",
        "# img_route = project_dir  + 'Train/MCI/067_S_0098_I65694_masked_basic.nii.gz'\n",
        "\n",
        "# # load in sitk format (SimpleITK)\n",
        "# sitk_image = sitk.ReadImage(img_route)\n",
        "# # transform into a numpy array\n",
        "# img = sitk.GetArrayFromImage(sitk_image)\n",
        "# print(np.expand_dims(img, axis=3).shape)\n",
        "# img = np.expand_dims(img, axis=3)\n",
        "# sample_shape = img.shape\n",
        "# # img = img / np.amax(img)\n",
        "# plt.imshow(img[:,:,100, 0], cmap='gray' )\n",
        "# plt.show()\n",
        "# print(img[60,:,100,:])\n",
        "# print(np.amax(img))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0xzkOpJO9n"
      },
      "source": [
        "# # Skip 50:-50 slices since there is not much to see\n",
        "# fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
        "# ax1.imshow(rotate(montage(img[24:-23,:,:,0]), -90, resize=True), cmap ='gray')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEpdk8rBpx3N",
        "outputId": "d2128206-113a-4c47-e5a1-014a67156fdd"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit([\"AD\", \"CN\", \"MCI\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcTRyqQfZ8ED"
      },
      "source": [
        "    # def __get_index(data_path):\n",
        "    #   files = [os.path.relpath(file_dir, data_path) for x in os.walk(data_path) for file_dir in glob(os.path.join(x[0], '*.nii.gz'))]\n",
        "    #   x_index = []\n",
        "    #   y_labels = []\n",
        "\n",
        "    #   for f in files:\n",
        "    #     f = f.split('/')\n",
        "    #     x_index.append(f[1])\n",
        "    #     y_labels.append(f[0])\n",
        "\n",
        "    #   y_labels = le.transform(y_labels)\n",
        "    #   # y_labels = to_categorical(y_labels, num_classes)\n",
        "\n",
        "    #   print(le.inverse_transform([y_labels[1]])[0])\n",
        "\n",
        "    #   return x_index, y_labels\n",
        "    \n",
        "    # a,b = __get_index(project_dir + '/Train/')\n",
        "    # print(type(a))\n",
        "    # print(type(b))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvD7ZmqZ51_z"
      },
      "source": [
        "Custom Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O0Nxebo589T"
      },
      "source": [
        "class DataGenerator(data_utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, data_path, dim=(192,192,160), batch_size = 1, n_channels = 1, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.data_path = data_path\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        self.list_IDs, self.Y_labels = self.__get_index(data_path)\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __get_index(self, data_path):\n",
        "        files = [os.path.relpath(file_dir, data_path) for x in os.walk(data_path) for file_dir in glob(os.path.join(x[0], '*.nii.gz'))]\n",
        "        x_index = []\n",
        "        y_labels = []\n",
        "\n",
        "        for f in files:\n",
        "            f = f.split('/')\n",
        "            x_index.append(f[1])\n",
        "            y_labels.append(f[0])\n",
        "\n",
        "        y_labels = le.transform(y_labels)\n",
        "        # y_labels = to_categorical(y_labels, num_classes)\n",
        "\n",
        "        return x_index, y_labels\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index): #Index denotes the current batch on an epoch\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
        "        Batch_Y = [self.Y_labels[k] for k in indexes]\n",
        "        \n",
        "        # Generate data\n",
        "        X = self.__data_generation(Batch_ids, Batch_Y)\n",
        "\n",
        "        Batch_Y = to_categorical(Batch_Y, num_classes)\n",
        "\n",
        "        return X, Batch_Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, Batch_ids, Batch_Y):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, *self.dim, self.n_channels))\n",
        "\n",
        "        # Generate data\n",
        "        for c, i in enumerate(Batch_ids): #count, element\n",
        "            case_path = os.path.join(self.data_path, le.inverse_transform([Batch_Y[c]])[0])\n",
        "            img_path = os.path.join(case_path, i);\n",
        "\n",
        "            # load nibabel Method\n",
        "            img = nib.load(img_path).get_fdata()    \n",
        "\n",
        "            # # One more dimension for the channels\n",
        "            img = np.expand_dims(img, axis=3)\n",
        "\n",
        "            X[c,:,:,:,:] = resize(img, (self.dim[0], self.dim[1], self.dim[2], 1))\n",
        "        return X/np.max(X) #We normalize between 0 an 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txs_TJ6U60HY"
      },
      "source": [
        "# import time\n",
        "\n",
        "# X = ['023_S_0139_I31300_masked_basic.nii.gz',\n",
        "#   '023_S_0139_I52066_masked_basic.nii.gz',\n",
        "#   '023_S_0139_I81883_masked_basic.nii.gz',\n",
        "#   '023_S_1262_I103322_masked_basic.nii.gz',\n",
        "#   '023_S_1262_I62433_masked_basic.nii.gz',\n",
        "#   '023_S_1262_I76649_masked_basic.nii.gz',\n",
        "#   '057_S_1373_I80258_masked_basic.nii.gz',\n",
        "#   '141_S_1152_I102067_masked_basic.nii.gz',\n",
        "#   '141_S_1152_I48590_masked_basic.nii.gz',\n",
        "#   '141_S_1152_I79410_masked_basic.nii.gz']\n",
        "# Y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "# data_path = project_dir + '/Train/'\n",
        "# dim = (192,192,160)\n",
        "# # batch_size = 10\n",
        "# # n_channels = 1\n",
        "\n",
        "# # def __data_generation(Batch_ids, Batch_Y):\n",
        "# #         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "# #         # Initialization\n",
        "# #         X = np.zeros((batch_size, *dim, n_channels))\n",
        "\n",
        "# #         # Generate data\n",
        "# #         for c, i in enumerate(Batch_ids): #count, element\n",
        "# #             case_path = os.path.join(data_path, le.inverse_transform([Batch_Y[c]])[0])\n",
        "# #             img_path = os.path.join(case_path, i);\n",
        "\n",
        "# #             # load nibabel Method\n",
        "# #             img = nib.load(img_path).get_fdata()    \n",
        "\n",
        "# #             # # load in sitk format (SimpleITK Method)\n",
        "# #             # sitk_image = sitk.ReadImage(img_path)\n",
        "# #             # # transform into a numpy array\n",
        "# #             # img = sitk.GetArrayFromImage(sitk_image)\n",
        "\n",
        "# #             # img = np.swapaxes(img,0,2)\n",
        "# #             # img = np.swapaxes(img,1,2)\n",
        "# #             # One more dimension for the channels\n",
        "# #             img = np.expand_dims(img, axis=3)\n",
        "\n",
        "# #             X[c,:,:,:,:] = img;\n",
        "# #         return X/np.max(X) #We normalize between 0 an 1\n",
        "\n",
        "# def __data_generation(Batch_ids, Batch_Y):\n",
        "#     'Generates data containing batch_size samples'\n",
        "#     # Initialization\n",
        "#     X = np.zeros((batch_size, *dim, n_channels))\n",
        "\n",
        "#     # Generate data\n",
        "#     for c, i in enumerate(Batch_ids): #count, element\n",
        "#         case_path = os.path.join(data_path, le.inverse_transform([Batch_Y[c]])[0])\n",
        "#         img_path = os.path.join(case_path, i);\n",
        "\n",
        "#         # load nibabel Method\n",
        "#         img = nib.load(img_path).get_fdata()    \n",
        "\n",
        "#         # # One more dimension for the channels\n",
        "#         img = np.expand_dims(img, axis=3)\n",
        "\n",
        "#         X[c,:,:,:,:] = img;\n",
        "#     return X/np.max(X) #We normalize between 0 an 1\n",
        "        \n",
        "# t1 = time.time()\n",
        "# img_data = __data_generation(X,Y)\n",
        "# t2 = time.time()\n",
        "# print(t2-t1)\n",
        "# print('segundos')\n",
        "# print(img_data.shape)\n",
        "# print(type(img_data))\n",
        "\n",
        "# for img in img_data:\n",
        "#   # fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
        "#   # ax1.imshow(rotate(montage(img[24:-23,:,:,0]), -90, resize=True), cmap ='gray')\n",
        "#   plt.imshow(img[:,:,72, 0], cmap='gray' )\n",
        "#   plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V915ioxmRR6V"
      },
      "source": [
        "# from pathlib import Path\n",
        "# list(Path(project_dir).rglob(\"*.[nN][iI][iI].[gG][zZ]\"))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJWB1hfSWTX"
      },
      "source": [
        "# import os\n",
        "# from glob import glob\n",
        "# files = [os.path.relpath(file_dir, project_dir) for x in os.walk(project_dir) for file_dir in glob(os.path.join(x[0], '*.nii.gz'))]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU77qLvrVJ16"
      },
      "source": [
        "# import os\n",
        "  \n",
        "# # Path\n",
        "# path = 'drive/MyDrive/Colab Notebooks/TFM/DATA/Train/CN/098_S_0896_I56031_masked_basic.nii.gz'\n",
        "  \n",
        "# # Path of Start directory\n",
        "# start = project_dir\n",
        "  \n",
        "# # Compute the relative file path\n",
        "# # to the given path from the \n",
        "# # the given start directory.\n",
        "# relative_path = os.path.relpath(path, start)\n",
        "  \n",
        "# # Print the relative file path\n",
        "# # to the given path from the \n",
        "# # the given start directory.\n",
        "# print(relative_path)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiPwA_o6Hi9O"
      },
      "source": [
        "**Prepare data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beEBdPc-HlS_"
      },
      "source": [
        "training_generator = DataGenerator(data_path=project_dir + '/Train/',\n",
        "                                   dim=images_shape,\n",
        "                                   batch_size = batch_size,\n",
        "                                   n_channels = n_channels,\n",
        "                                   shuffle=True)\n",
        "# valid_generator = DataGenerator(val_ids)\n",
        "test_generator = DataGenerator(data_path=project_dir + '/Test/',\n",
        "                                   dim=images_shape,\n",
        "                                   batch_size = batch_size,\n",
        "                                   n_channels = n_channels,\n",
        "                                   shuffle=False)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHuqA1b6y_vR"
      },
      "source": [
        "# print('len ', str(training_generator.__len__()))\n",
        "# print(type(training_generator.__len__()))\n",
        "# print('len ', str(len(training_generator)))\n",
        "# # X, y = training_generator.__getitem__(1)\n",
        "# X, y = training_generator[1]\n",
        "\n",
        "# plt.imshow(X[8,:,:,72, 0], cmap='gray' )\n",
        "# plt.show()\n",
        "\n",
        "# print(type(training_generator))\n",
        "# # y\n",
        "# # X"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ6JV7nvAAXR"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-KMog9ACyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a4add4-76c7-4bd4-f10e-dfd516f18254"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "sample_shape=(192,192,160,1)\n",
        "# Create the model\n",
        "# model = Sequential()\n",
        "# model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
        "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# # model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "# # model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# # model.add(BatchNormalization(center=True, scale=True))\n",
        "# # model.add(Dropout(0.5))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# from resnet3d import Resnet3DBuilder\n",
        "# base_model = Resnet3DBuilder.build_resnet_18(\n",
        "#     input_shape=sample_shape,\n",
        "#     num_outputs=num_classes,\n",
        "#     reg_factor=0.04\n",
        "# )\n",
        "\n",
        "# # add the final layers and compile\n",
        "# fc_layer = tf.keras.layers.Dense(512, activation='relu')(base_model.layers[-2].output)\n",
        "# fc_layer = tf.keras.layers.Dropout(0.8)(fc_layer)\n",
        "# output_layer = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(fc_layer)\n",
        "# model = tf.keras.models.Model(inputs=base_model.input, outputs=output_layer)\n",
        "# optimizer = tf.keras.optimizers.Adam(lr=0.00001)\n",
        "# model.compile(optimizer=optimizer, \n",
        "#               loss='categorical_crossentropy', \n",
        "#               metrics=['acc'])\n",
        "\n",
        "# # train the model\n",
        "# model.fit(x=image_tensor, y=label_tensor, epochs=50, \n",
        "#           steps_per_epoch=STEPS_PER_EPOCH, \n",
        "#           validation_data=val_tensor, \n",
        "#           validation_steps=VALIDATION_STEPS)\n",
        "\n",
        "\n",
        "def get_model(width=192, height=192, depth=160):\n",
        "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "    inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = MaxPool3D(pool_size=2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = MaxPool3D(pool_size=2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = MaxPool3D(pool_size=2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = MaxPool3D(pool_size=2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = GlobalAveragePooling3D()(x)\n",
        "    x = Dense(units=512, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    outputs = Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model.\n",
        "model = get_model(width=192, height=192, depth=160)\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"3dcnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 192, 192, 160, 1) 0         \n",
            "_________________________________________________________________\n",
            "conv3d (Conv3D)              (None, 190, 190, 158, 64) 1792      \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 95, 95, 79, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 95, 95, 79, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 93, 93, 77, 64)    110656    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 46, 46, 38, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 46, 46, 38, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 44, 44, 36, 128)   221312    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 22, 22, 18, 128)   0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 22, 22, 18, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 20, 20, 16, 256)   884992    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 10, 10, 8, 256)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 8, 256)    1024      \n",
            "_________________________________________________________________\n",
            "global_average_pooling3d (Gl (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,352,897\n",
            "Trainable params: 1,351,873\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFsqpPJRlf3J"
      },
      "source": [
        "# plot_model(model, \n",
        "#            show_shapes = True,\n",
        "#            show_dtype=False,\n",
        "#            show_layer_names = True, \n",
        "#            rankdir = 'TB', \n",
        "#            expand_nested = False, \n",
        "#            dpi = 70)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPwDKMduPH3b"
      },
      "source": [
        "opt = Adam(0.001, decay=1e-6)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmyJqaF_O6h4"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcYUb-uAO8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b0c966-edc1-4959-ee2d-e8dcf14c41a5"
      },
      "source": [
        "# Fit data to model\n",
        "history = model.fit(x=training_generator,\n",
        "                    # batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data = test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/30 [=========>....................] - ETA: 20:31 - loss: 1.1921e-07 - accuracy: 0.5000"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}