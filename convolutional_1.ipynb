{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "convolutional_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17VBdqomreofRALqlfF0XsI5hEQfrX4-E",
      "authorship_tag": "ABX9TyOc/WPZz6spf7zFn0qp1JO2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('pruebas_env': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "2fb176d0394d4e3eb5a4919b2d839568523166680b760a18060413ce7022ce94"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Install dependencies\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RurXunB-6nMi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# !pip install tensorflow-gpu==2.3 keras simpleitk matplotlib scikit-image pandas cupy"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10PyY7GC6uCw",
        "outputId": "d4d77646-0d9b-4085-a992-82e015f426b1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# pip uninstall tensorflow-gpu tensorflow keras"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# pip install git+https://github.com/JihongJu/keras-resnet3d.git"
      ],
      "outputs": [],
      "metadata": {
        "id": "HZjU4w5ofRBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Packages"
      ],
      "metadata": {
        "id": "CZLhEj--wJHW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #then these two lines force keras to use your CPU\n",
        "# import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "# from keras.layers import Dense, Dropout, Activation, Flatten, Lambda\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization as BN\n",
        "# from keras.layers import GaussianNoise as GN\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, MaxPool3D, GlobalAveragePooling3D, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras.utils import Sequence\n",
        "# from tensorflow.python.keras.utils import data_utils\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data\n",
        "from skimage.util import montage \n",
        "# from skimage.util.montage import montage2d\n",
        "import skimage.transform as skTrans\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "# from sklearn import preprocessing\n",
        "# import pandas as pd\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import SimpleITK as sitk\n",
        "# import nibabel as nib"
      ],
      "outputs": [],
      "metadata": {
        "id": "-7hrgrNuu1KS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and prepare data**"
      ],
      "metadata": {
        "id": "znqIEoxb4034"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# project_dir = \"drive/MyDrive/Colab Notebooks/TFM/DATA/\"\n",
        "\n",
        "project_dir = \"/home/pmeslaf/TFM/DATA/FIRST_VISIT_DATA_nougmented/\""
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucs3UqFi5ok8",
        "outputId": "d7d94588-f981-4d7f-dc2d-8f06ff386811"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "# assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "# config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "# config = tf.config.experimental.set_memory_growth(physical_devices[1], True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "batch_size = 2\n",
        "epochs = 100\n",
        "shape=128\n",
        "classes = [\"MCI\", \"AD\", \"CN\"]\n",
        "num_classes = len(classes) \n",
        "n_channels = 1\n",
        "images_shape = (shape,shape,int(shape), n_channels)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qo3skwY9J8Gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Image Generator"
      ],
      "metadata": {
        "id": "DvD7ZmqZ51_z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from data_generator import DataGenerator"
      ],
      "outputs": [],
      "metadata": {
        "id": "0O0Nxebo589T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare data**"
      ],
      "metadata": {
        "id": "jiPwA_o6Hi9O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training_generator = DataGenerator(data_path=project_dir + '/Train/',\n",
        "                                   dim=images_shape[:-1],\n",
        "                                   batch_size = batch_size,\n",
        "                                   n_channels = n_channels,\n",
        "                                   classes = classes,\n",
        "                                #    flip=True,\n",
        "                                #    zoom=1.5,\n",
        "                                #    rotation=10,\n",
        "                                   fourth_axis = False,\n",
        "                                   shuffle=True)\n",
        "valid_generator = DataGenerator(data_path=project_dir + '/Validation/',\n",
        "                                   dim=images_shape[:-1],\n",
        "                                   batch_size = batch_size,\n",
        "                                   n_channels = n_channels,\n",
        "                                   classes = classes,\n",
        "                                   test=True,\n",
        "                                   fourth_axis = False,\n",
        "                                   shuffle=True)\n",
        "test_generator = DataGenerator(data_path=project_dir + '/Test/',\n",
        "                                   dim=images_shape[:-1],\n",
        "                                   batch_size = batch_size,\n",
        "                                   n_channels = n_channels,\n",
        "                                   classes = classes,\n",
        "                                   test=True,\n",
        "                                   fourth_axis = False,\n",
        "                                   shuffle=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "beEBdPc-HlS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from Distort import Distort, GaussianDistortion\n",
        "\n",
        "X, y = training_generator[0]\n",
        "image = X[1]\n",
        "print(image.shape)\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for i in range(9):\n",
        "#   ax = plt.subplot(3, 3, i + 1)\n",
        "#   plt.imshow(image[i*10,:,:])\n",
        "#   plt.axis(\"off\")\n",
        "# plt.show()\n",
        "\n",
        "deformador = Distort(4, 4, 8)\n",
        "deformador_gaussiano = GaussianDistortion(3, 3, 30, \"bell\", \"in\", 1.0, 1.0, 1.0, 1.0)\n",
        "# augmented_img = deformador.perform_operation(image)\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for i in range(9):\n",
        "#   ax = plt.subplot(3, 3, i + 1)\n",
        "#   plt.imshow(augmented_img[i*10,:,:])\n",
        "#   plt.axis(\"off\")\n",
        "# plt.show()\n",
        "\n",
        "augmented_img = deformador_gaussiano.perform_operation(image)\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(0,24,2):\n",
        "  ax = plt.subplot(5, 5, i + 1)\n",
        "  plt.imshow(image[i*3,:,:])\n",
        "  plt.axis(\"off\")\n",
        "  ax = plt.subplot(5, 5, i + 2)\n",
        "  plt.imshow(augmented_img[i*3,:,:])\n",
        "  plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(0,24,2):\n",
        "  ax = plt.subplot(5, 5, i + 1)\n",
        "  plt.imshow(image[:,:,i*3])\n",
        "  plt.axis(\"off\")\n",
        "  ax = plt.subplot(5, 5, i + 2)\n",
        "  plt.imshow(augmented_img[:,:,i*3])\n",
        "  plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from vox_cnn_pseudo3D import voxCNN_pseudo3D\n",
        "# from vox_cnn_p\n",
        "# seudo3D_v2 import voxCNN_pseudo3D_V2\n",
        "# from vox_cnn_pseudo3D_v3 import voxCNN_pseudo3D_V3\n",
        "\n",
        "# model = voxCNN_pseudo3D(input_shape=images_shape[:-1], n_classes=num_classes) # batch=32\n",
        "\n",
        "# # model.load_weights(project_dir + 'VoxCNN_pseudoRGB_E87_AD-CN_128_23-09-2021_01-19.0.8164.m5')\n",
        "\n",
        "# pseudoRGB=model.get_layer('block0_pseudoRGB')\n",
        "\n",
        "# X, y = training_generator[0]\n",
        "# image = X[1]\n",
        "# print(image.shape)\n",
        "\n",
        "# # Add the image to a batch\n",
        "# image = tf.expand_dims(image, 0)\n",
        "\n",
        "# plt.figure(figsize=(20, 20))\n",
        "# for i in range(9):\n",
        "#   ax = plt.subplot(5, 5, i + 1)\n",
        "#   augmented_image = pseudoRGB(image, training=True)\n",
        "#   # print(augmented_image.shape)\n",
        "#   plt.imshow(augmented_image[0])\n",
        "#   plt.axis(\"off\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "nHuqA1b6y_vR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "data_augmentation = Sequential([\n",
        "  # layers.experimental.preprocessing.RandomFlip(\"vertical\"),\n",
        "  layers.experimental.preprocessing.RandomContrast(0.9),\n",
        "  # layers.experimental.preprocessing.RandomRotation(0.2, fill_mode='nearest'), #nearest\n",
        "  # layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1, fill_mode='nearest'),\n",
        "  # layers.experimental.preprocessing.RandomZoom(height_factor=0.3, fill_mode='nearest'),\n",
        "  # layers.Conv2D(3, (3, 3), activation='relu', padding='same'),\n",
        "])\n",
        "\n",
        "X, y = test_generator[0]\n",
        "image = X[1]\n",
        "print(image.shape)\n",
        "# plt.imshow(image[:,:,50], cmap ='gray')\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(25):\n",
        "  ax = plt.subplot(5, 5, i + 1)\n",
        "  # print(augmented_image.shape)\n",
        "  plt.imshow(image[:,:,i*3])\n",
        "  plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Add the image to a batch\n",
        "image = tf.expand_dims(image, 0)\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(25):\n",
        "  ax = plt.subplot(5, 5, i + 1)\n",
        "  augmented_image = data_augmentation(image, training=True)\n",
        "  # print(augmented_image.shape)\n",
        "  plt.imshow(augmented_image[0,:,:,i*3])\n",
        "  plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "px = 1/plt.rcParams['figure.dpi']\n",
        "\n",
        "fig, ax1 = plt.subplots(1, 1, figsize = (770*px,770*px))\n",
        "ax1.imshow(montage(image[0,:,:,:]), cmap ='gray')\n",
        "plt.show()\n",
        "fig, ax1 = plt.subplots(1, 1, figsize = (770*px,770*px))\n",
        "ax1.imshow(montage(augmented_image[0,:,:,:]), cmap ='gray')\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "px = 1/plt.rcParams['figure.dpi']\n",
        "X, y = training_generator[1]\n",
        "# X = resize(X[:,5:-5,:,:],  (X.shape[0], 36, X.shape[2], X.shape[3]))\n",
        "fig, ax1 = plt.subplots(1, 1, figsize = (770*px,770*px))\n",
        "\n",
        "ax1.imshow(montage(X[:,:,:,50,0]), cmap ='gray')\n",
        "plt.show()\n",
        "# plt.imshow(montage(X[1,:,:,:,0]), cmap ='gray')\n",
        "# plt.show()\n",
        "# plt.imshow(montage(X[2,:,:,:,0]), cmap ='gray')\n",
        "# plt.show()\n",
        "# plt.imshow(montage(X[3,:,:,:,0]), cmap ='gray')\n",
        "# plt.show()\n",
        "\n",
        "# img = X[0,:,:,:,0]\n",
        "# plt.imshow(img[:,:,50], cmap ='gray')\n",
        "# plt.show()\n",
        "# plt.imshow(img[:,50,:], cmap ='gray')\n",
        "# plt.show()\n",
        "# plt.imshow(img[50,:,:], cmap ='gray')\n",
        "# plt.show()\n",
        "\n",
        "# img =  np.flip(img, 2)\n",
        "\n",
        "# plt.imshow(img[:,:,50], cmap ='gray')\n",
        "# plt.show()\n",
        "# plt.imshow(img[:,50,:], cmap ='gray')\n",
        "# plt.show()\n",
        "# plt.imshow(img[50,:,:], cmap ='gray')\n",
        "# plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(X[:,:,:,:,0].shape)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# print(X[0,14,:,:,0])\n",
        "# print(X[10,14,:,:,0])\n",
        "# print(X[7,14,:,:,0])\n",
        "# print(X[34,14,:,:,0])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plt.imshow(X[0,:,:,50, 0], cmap='gray' )\n",
        "# plt.show()\n",
        "# plt.imshow(X[0,:,25,:, 0], cmap='gray' )\n",
        "# plt.show()\n",
        "# plt.imshow(X[0,60,:,:, 0], cmap='gray' )\n",
        "# plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL**"
      ],
      "metadata": {
        "id": "RJ6JV7nvAAXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from tensorflow.keras.models import Model\n",
        "# sample_shape=(192,192,160,1)\n",
        "# Create the model\n",
        "# model = Sequential()\n",
        "# model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
        "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# # model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "# # model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# # model.add(BatchNormalization(center=True, scale=True))\n",
        "# # model.add(Dropout(0.5))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# from resnet3d import Resnet3DBuilder\n",
        "# base_model = Resnet3DBuilder.build_resnet_18(\n",
        "#     input_shape=sample_shape,\n",
        "#     num_outputs=num_classes,\n",
        "#     reg_factor=0.04\n",
        "# )\n",
        "\n",
        "# # add the final layers and compile\n",
        "# fc_layer = tf.keras.layers.Dense(512, activation='relu')(base_model.layers[-2].output)\n",
        "# fc_layer = tf.keras.layers.Dropout(0.8)(fc_layer)\n",
        "# output_layer = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(fc_layer)\n",
        "# model = tf.keras.models.Model(inputs=base_model.input, outputs=output_layer)\n",
        "# optimizer = tf.keras.optimizers.Adam(lr=0.00001)\n",
        "# model.compile(optimizer=optimizer, \n",
        "#               loss='categorical_crossentropy', \n",
        "#               metrics=['acc'])\n",
        "\n",
        "# # train the model\n",
        "# model.fit(x=image_tensor, y=label_tensor, epochs=50, \n",
        "#           steps_per_epoch=STEPS_PER_EPOCH, \n",
        "#           validation_data=val_tensor, \n",
        "#           validation_steps=VALIDATION_STEPS)\n",
        "\n",
        "\n",
        "# def get_model(width=192, height=192, depth=160):\n",
        "#     \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "#     inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "#     x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "#     x = MaxPool3D(pool_size=2)(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = MaxPool3D(pool_size=2)(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = MaxPool3D(pool_size=2)(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = MaxPool3D(pool_size=2)(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "\n",
        "#     x = GlobalAveragePooling3D()(x)\n",
        "#     x = Dense(units=512, activation=\"relu\")(x)\n",
        "#     x = Dropout(0.3)(x)\n",
        "\n",
        "#     outputs = Dense(units=num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "#     # Define the model.\n",
        "#     model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "#     return model\n",
        "\n",
        "\n",
        "# # Build model.\n",
        "# model = get_model(width=192, height=192, depth=160)\n",
        "# model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "HN-KMog9ACyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a4add4-76c7-4bd4-f10e-dfd516f18254"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# batch_size = 16\n",
        "# epochs = 300\n",
        "# # frozen_epochs = 100\n",
        "# num_classes = 2\n",
        "# shape=110\n",
        "# images_shape = (shape,shape,int(shape))\n",
        "# n_channels = 1\n",
        "\n",
        "\n",
        "# project_dir = \"/home/pmeslaf/TFM/DATA/\"\n",
        "# from data_generator import DataGenerator\n",
        "\n",
        "# training_generator = DataGenerator(data_path=project_dir + '/Train/',\n",
        "#                                    dim=images_shape,\n",
        "#                                    batch_size = batch_size,\n",
        "#                                    n_channels = n_channels,\n",
        "#                                    num_classes=num_classes,\n",
        "#                                    shuffle=True,\n",
        "#                                    rotation=5)\n",
        "# valid_generator = DataGenerator(data_path=project_dir + '/Validation/',\n",
        "#                                    dim=images_shape,\n",
        "#                                    batch_size = batch_size,\n",
        "#                                    n_channels = n_channels,\n",
        "#                                    num_classes=num_classes,\n",
        "#                                    shuffle=True)\n",
        "# test_generator = DataGenerator(data_path=project_dir + '/Test/',\n",
        "#                                    dim=images_shape,\n",
        "#                                    batch_size = batch_size,\n",
        "#                                    n_channels = n_channels,\n",
        "#                                    num_classes=num_classes,\n",
        "#                                    shuffle=True)\n",
        "\n",
        "\n",
        "# # # Create a callback that saves the model's weights\n",
        "# checkpoint_path = project_dir + 'model_.{epoch:02d}-{val_loss:.6f}.m5'\n",
        "# callbacks_list = [\n",
        "#             # EarlyStopping(monitor='loss',\n",
        "#             #               min_delta=0,\n",
        "#             #               patience=2,\n",
        "#             #               verbose=1,\n",
        "#             #               mode='auto'),\n",
        "#             ReduceLROnPlateau(monitor='val_loss',\n",
        "#                               factor=0.1,\n",
        "#                               patience=3,\n",
        "#                               min_lr=0.000001,\n",
        "#                               verbose=1),\n",
        "#             ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                             # monitor='val_accuracy',\n",
        "#                             # mode='max',\n",
        "#                             monitor='val_loss',\n",
        "#                             mode='min',\n",
        "#                             verbose=1,\n",
        "#                             save_best_only=True,\n",
        "#                             save_weights_only = True),\n",
        "#             CSVLogger( project_dir + 'training.log',\n",
        "#                       separator=',',\n",
        "#                       append=False)\n",
        "#     ]\n",
        "\n",
        "\n",
        "\n",
        "# # **MODEL**\n",
        "\n",
        "# def CBGN(model,filters,lname,ishape=0):\n",
        "#   if (ishape!=0):\n",
        "#     model.add(Conv3D(filters=filters, kernel_size=3, activation=\"relu\",\n",
        "#                  input_shape=ishape))\n",
        "#   else:\n",
        "#     model.add(Conv3D(filters=filters, kernel_size=3, activation=\"relu\"))\n",
        "\n",
        "#   # model.add(MaxPool3D(pool_size=2,name=lname))\n",
        "  \n",
        "#   return model\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# model=CBGN(model,8,'conv_model_1',(images_shape[0], images_shape[1], images_shape[2], 1))\n",
        "# model=CBGN(model,8,'conv_model_2')\n",
        "# model.add(MaxPool3D(pool_size=2))\n",
        "# model=CBGN(model,16,'conv_model_3')\n",
        "# model=CBGN(model,16,'conv_model_4')\n",
        "# model.add(MaxPool3D(pool_size=2))\n",
        "# model=CBGN(model,32,'conv_model_5')\n",
        "# model=CBGN(model,32,'conv_model_6')\n",
        "# model=CBGN(model,32,'conv_model_7')\n",
        "# model.add(MaxPool3D(pool_size=2))\n",
        "# model=CBGN(model,64,'conv_model_8')\n",
        "# model=CBGN(model,64,'conv_model_9')\n",
        "# model=CBGN(model,64,'conv_model_10')\n",
        "# model.add(MaxPool3D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(units=128))\n",
        "# model.add(BN())\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(units=64, activation=\"relu\"))\n",
        "\n",
        "# model.add(Dense(num_classes))\n",
        "# model.add(Activation('softmax'))\n",
        "# # model.add(Activation('sigmoid'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# opt = Adam(0.000001, decay=1e-6)\n",
        "\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=opt,\n",
        "#               metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plot_model(model, \n",
        "#            show_shapes = True,\n",
        "#            show_dtype=False,\n",
        "#            show_layer_names = True, \n",
        "#            rankdir = 'TB', \n",
        "#            expand_nested = False, \n",
        "#            dpi = 70)"
      ],
      "outputs": [],
      "metadata": {
        "id": "sFsqpPJRlf3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from resnet3d import Resnet3DBuilder\n",
        "# model = Resnet3DBuilder.build_resnet_50((images_shape[0], images_shape[1], images_shape[2], 1), num_classes)\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# model.fit(X_train, y_train, batch_size=32)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# opt = Adam(0.000001, decay=1e-6)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QPwDKMduPH3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# # Compile the model\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=opt,\n",
        "#             #   metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "PmyJqaF_O6h4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# model.load_weights(project_dir + 'model_.293-0.515146.m5')\n",
        "#  # Fit data to model\n",
        "# history = model.fit(x=training_generator,\n",
        "#                     epochs=epochs,\n",
        "#                     verbose=1,\n",
        "#                     validation_data = test_generator)"
      ],
      "outputs": [],
      "metadata": {
        "id": "dcYUb-uAO8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b0c966-edc1-4959-ee2d-e8dcf14c41a5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# history = pd.read_csv(project_dir + 'training.log', sep=',', engine='python')\n",
        "# plt.plot(history['accuracy'])\n",
        "# plt.plot(history['val_accuracy'])\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'val'], loc='upper left')\n",
        "# plt.savefig(project_dir + 'evolution_training.png')\n",
        "\n",
        "\n",
        "# predictions = model.evaluate(test_generator)\n",
        "# # score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# print('Test loss:', predictions[0])\n",
        "# print('Test accuracy:', predictions[1])\n"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}